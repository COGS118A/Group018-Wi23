{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Simon Zheng\n",
    "- Albert Henderson\n",
    "- Zhengyuan Zhou\n",
    "- Abhinav Chandra\n",
    "- Sung Cho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The goal of this project is to develop a machine-learning algorithm that can accurately classify stars into galaxies, quasars, and stars. The dataset used is the Sloan Digital Sky Survey (SDSS), and it contains observations of stars including 17 feature columns and 1 class column. We will preprocess the data by cleaning and extracting useful features before training a machine learning algorithm, specifically the K-nearest neighbors method(KNN), to classify the stars. The primary measure of success will be accuracy in correctly classifying the stars, which can be described as the total number of correct classifications over the total number of observations. We believe that through this project, we can develop a way to classify stars more accurately and more efficiently, thus enhancing our understanding of the universe and even possibly narrowing the range of habitable planets.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Kepler-438b is a rocky planet discovered in 2015 that is located 640 light-years from Earth in the constellation Lyra, with a mass of 1.46 Earths<sup>[1]</sup>. What makes it special is that Kepler-438b locates right on the habitable zone of its parent star (0.166 AU), making the temperature just right for water to exist in a liquid state<sup>[2]</sup>. This means that if one day humans have to migrate to another planet, Kepler-438b becomes a potential second earth, and this finding can also indicate that life might exist on Kepler-438b. \n",
    "\n",
    "Other than Kepler-438b, scientists have found 11 more small Kepler transiting planets located in the habitable zone, and using techniques such as big data analysis and supervised machine learning, we could possibly find more habitable planets with higher efficiency compared to traditional methods of stellar classification. Bailer-Jones, for instance, pointed out in their paper that “current and future large astronomical surveys will yield multiparameter databases on millions or even billions of objects”<sup>[3]</sup>, which is why it becomes necessary to let computers do the work instead of manually classifying and labeling all the stars. They also discussed how the technique of unsupervised machine learning does not work well, because it produces “natural groupings” instead of groupings based on definitions provided by astrologists. \n",
    "\n",
    "Similarly, Baqui also acknowledged the challenges presented with large datasets and successfully implemented machine learning algorithms such as K-nearest neighbors, decision trees, random forest (RF), and artificial neural networks to train and classify stars<sup>[4]</sup>. With these previous successful examples, we believe that we can also use supervised machine learning algorithms to classify galaxies, quasars, and stars using features such as ascension, declination, or filters of the photometric system<sup>[5]</sup>. Though challenges such as outlier detection and handling sparse datasets commonly exist for the task of stellar classification<sup>[6]</sup>, we will do our best to address these problems."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The vast universe has always fascinated us, and we have been exploring the stars and galaxies for centuries. What if we could develop a machine learning model that could accurately classify astronomical objects based on their spectral characteristics?\n",
    "\n",
    "Our goal is to build a state-of-the-art model that can accurately classify stars, galaxies, and quasars using the SDSS dataset. With 17 feature columns and 1 class column, we have a treasure trove of information waiting to be unlocked. Imagine being able to predict the class of an astronomical object with high accuracy, opening up a new era of space exploration and discovery.\n",
    "\n",
    "We can use advanced techniques like deep learning and ensemble models to achieve the highest accuracy possible. With cutting-edge evaluation techniques like cross-validation and hyperparameter tuning, we can fine-tune our model to perfection. We can measure the accuracy of our model using precision, recall, F1 score, and confusion matrix, and we can observe the performance of our model through testing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset that we are planning to work with is the 17th data release of the Sloan Digital Sky Survey, and it can be found [here](https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17). This data was collected to perform a stellar classification task and it contains 100000 observations. Each observation contains 17 feature variables that describe various aspects of the observation and 1 class variable that labels the class of the observation as either a galaxy, star, or quasar object. \n",
    "\n",
    "Of the 17 features that each observation has, 5 of these features are used for identification of the observation (obj_id, run_id, rerun_id, field_id, spec_obj_id) and 4 other features are used to describe different aspects about how the data was captured.(cam_col, plate, MJD, fiber_ID). The features used for identification help researchers keep track of each observation, which is an arduous task with 100000 observation. The features used to describe data collection are also critical for researchers to keep track of as they detail the circumstances that led to the recording of each observation. However, for a machine learning classification task, this data is not of utmost importance. The remaining 8 variables are all crucial to classifying the celestial body. These variables are:\n",
    "\n",
    "- alpha: Right ascension angle at J200 epoch\n",
    "- delta: Declination angle at J200 epoch\n",
    "- u: ultraviolet filter in the photometric system\n",
    "- g: green filter in the photometric system\n",
    "- r: red filter in the photometric system\n",
    "- i: near infrared filter in the photometric system\n",
    "- z: infrared filter in the photometric system\n",
    "- redshift: redshift value based on the increase in wavelength\n",
    "\n",
    "All of these variables hold continuous floating point values, so they will be normalized using z-scores. The class feature that labels the observation is a categorical feature, and this will be one hot encoded. \n",
    "\n",
    "As far as cleaning this dataset, the features used for identification and to describe data collection will likely be dropped. The obj_id field may be kept to ensure there is one identification field. This would result in the dataset being cut down to 10 variables in total, with 8 feature variables, 1 identification variable, and 1 class variable. Also, using all 100000 observations may prove to be too much of a computational burden to work with, in which case we would randomly sample a smaller subset of the larger dataset and work with that to build our classifier."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To solve the classification problem of astronomical objects, we propose building a K-nearest neighbors (KNN) model using cross-validation to benchmark our model. \n",
    "\n",
    "We will start by preprocessing the data, which includes normalizing the feature columns and converting the class column into categorical labels. We will then use cross-validation to split the dataset into training and testing sets, ensuring that the data is well-distributed across both sets.\n",
    "\n",
    "For the KNN model, we will choose the number of neighbors (k) based on the performance on the validation set. We will use a distance metric, such as Euclidean or Manhattan, to calculate the distance between data points. We will train the KNN model using the training set and evaluate its performance on the testing set. We will use accuracy as the primary metric to evaluate the performance of the KNN model. We will also report the precision, recall, and F1 score to assess the model's performance in each class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Accuracy is the primary metric we will use to quantify performance. Accuracy is a measure of the proportion of observations that were classified correctly. In the case of a binary classification, it could be represented like this:\n",
    "$$Accuracy = \\frac{True Positives + True Negatives}{Total No. of Observations}$$\n",
    "However, our classifier is working with multiple classes, so calculating accuracy for our classifier would be to alter the equation to:\n",
    "$$Accuracy = \\frac{Total No. of Correct Classifications}{Total No. of Observations}$$\n",
    "For example, if our model is being tested on 100 observations, and 26 were correctly classified as stars, 28 were correctly classified as galaxies, and 36 were correctly classified as quasar objects, the accuracy would be 0.80. Accuracy is a good measure for this task since our main goal is to classify as many observations correctly as possible.\n",
    "\n",
    "The F1 score, precision, and recall would also be a useful to help gain a better insight on specific aspects of model performance. These metrics can be calculated by:\n",
    "\n",
    "$$precision = \\frac{True Positives}{True Positive + False Positives}$$\n",
    "\n",
    "$$recall = \\frac{True Positives}{True Positives + False Negatives}$$\n",
    "\n",
    "$$F1 = \\frac{2(precison)(recall)}{precision + recall}$$\n",
    "\n",
    "Precision gives us the proportion of objects that have been correctly classified with respect to all the objects that have been classified in that class. Recall gives us what proportion of a certain class has been correctly classified. F1 score gives us a harmonic mean of precision and recall. Because this is a multi class classifier, this metrics can be measured for each class. For example, out of a 100 objects labelled as galaxies by our classifier, if 93 are actually galaxies, precision is 0.93. Similarly, for 100 actual galaxies, if 88 are correctly classified as galaxies, recall is 0.88. The F1 score would then be 0.90."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import Packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(style='seaborn-deep')\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic information of the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   obj_ID       100000 non-null  float64\n",
      " 1   alpha        100000 non-null  float64\n",
      " 2   delta        100000 non-null  float64\n",
      " 3   u            100000 non-null  float64\n",
      " 4   g            100000 non-null  float64\n",
      " 5   r            100000 non-null  float64\n",
      " 6   i            100000 non-null  float64\n",
      " 7   z            100000 non-null  float64\n",
      " 8   run_ID       100000 non-null  int64  \n",
      " 9   rerun_ID     100000 non-null  int64  \n",
      " 10  cam_col      100000 non-null  int64  \n",
      " 11  field_ID     100000 non-null  int64  \n",
      " 12  spec_obj_ID  100000 non-null  float64\n",
      " 13  class        100000 non-null  object \n",
      " 14  redshift     100000 non-null  float64\n",
      " 15  plate        100000 non-null  int64  \n",
      " 16  MJD          100000 non-null  int64  \n",
      " 17  fiber_ID     100000 non-null  int64  \n",
      "dtypes: float64(10), int64(7), object(1)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"star_classification.csv\")\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>rerun_ID</th>\n",
       "      <th>cam_col</th>\n",
       "      <th>field_ID</th>\n",
       "      <th>spec_obj_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>MJD</th>\n",
       "      <th>fiber_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>6.543777e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>5812</td>\n",
       "      <td>56354</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>4518</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>1.176014e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>10445</td>\n",
       "      <td>58158</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5.152200e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>4576</td>\n",
       "      <td>55592</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237663e+18</td>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>4192</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>1.030107e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>9149</td>\n",
       "      <td>58039</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>6.891865e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>6121</td>\n",
       "      <td>56187</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         obj_ID       alpha      delta         u         g         r  \\\n",
       "0  1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
       "1  1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
       "2  1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
       "3  1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
       "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
       "\n",
       "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
       "0  19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
       "1  21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
       "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
       "3  20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
       "4  15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
       "\n",
       "    class  redshift  plate    MJD  fiber_ID  \n",
       "0  GALAXY  0.634794   5812  56354       171  \n",
       "1  GALAXY  0.779136  10445  58158       427  \n",
       "2  GALAXY  0.644195   4576  55592       299  \n",
       "3  GALAXY  0.932346   9149  58039       775  \n",
       "4  GALAXY  0.116123   6121  56187       842  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Find out all the classes that we are goint to classify as__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GALAXY' 'QSO' 'STAR']\n"
     ]
    }
   ],
   "source": [
    "labels = data_df['class'].unique()\n",
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check if there are null values in the dataset, if yes, then remove them__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj_ID         0\n",
       "alpha          0\n",
       "delta          0\n",
       "u              0\n",
       "g              0\n",
       "r              0\n",
       "i              0\n",
       "z              0\n",
       "run_ID         0\n",
       "rerun_ID       0\n",
       "cam_col        0\n",
       "field_ID       0\n",
       "spec_obj_ID    0\n",
       "class          0\n",
       "redshift       0\n",
       "plate          0\n",
       "MJD            0\n",
       "fiber_ID       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_df.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out that the dataset has no null values and is good to use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now, we should select all the important features we want to build our models__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Stellar Classification\" project aims to use a dataset found on Kaggle to develop a machine learning model that can accurately classify celestial objects as galaxies, stars, or quasars. Like any project that deals with data and technology, there are several ethical and privacy considerations that need to be taken into account to ensure that the project is conducted responsibly and without causing harm to any individuals or groups.\n",
    "\n",
    "Since the dataset used in the project was obtained through observations from the Sloan Digital Sky Survey, it is important to carefully analyze the dataset to detect and address any potential biases that may exist in the data.\n",
    "\n",
    "The machine learning model should be designed in a way that is fair to all groups, without discriminating against any specific demographic. The model does not unfairly benefit one group over another, and that it is not used to discriminate against individuals or groups since it is merely a study of stellar objects.\n",
    "\n",
    "The machine learning model should be transparent and explainable, meaning that it is possible to understand how it works and how it makes classification decisions to prevent the model from being used in inappropriate ways.\n",
    "\n",
    "Personal information does not exist in the dataset to prevent the identification of individuals and protect privacy.\n",
    "\n",
    "In terms of data security, the datasets is published online transparently, so there is no potential problems such as unauthorized access, modification, or disclosure of the data.\n",
    "\n",
    "Individuals included in the dataset should be informed about how their data will be used and provided with the option to opt-out of having their data used in the project. Informed consent is critical to protecting the privacy of individuals and to ensuring that the project is conducted ethically. Since the dataset is officially published by Sloan Digital Sky Survey, it should be considered that everyone already given consent of the usage of this public dataset presumably.\n",
    "\n",
    "In conclusion, the project will be conducted with a strong emphasis on ethics and privacy to ensure that it is conducted responsibly and does not cause harm to individuals or groups. The project should be designed to be fair and transparent, with appropriate measures taken to protect the privacy of individuals included in the dataset. By taking these steps, the project can be conducted in an ethical and responsible manner, while still achieving its scientific objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* Have assigned work finished on time\n",
    "* Be vocal if you run into any difficulties with your sections\n",
    "* Be respectful when communicating with each other\n",
    "* All decisions will be handled by a group vote\n",
    "* Deadlines will be set as a group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 3/1  |  4 PM |  Submit Project Proposal |Discuss Objectives for the week and assign task to each member | \n",
    "| 3/7 |  4 PM |  Have assigned section finished or close to completed | Discuss what else needs to be done before checkpoint submission,Discuss what we want to do moving forward for the final submission |\n",
    "| 3/13  | 4 PM  | Noticable progress or revision on each section of project | Discuss how things are going and what else needs to be done |\n",
    "| 3/19 | 4 PM  | More work on assigned sections | Review the project overall and see if any revisions or changes need to be made before submission |\n",
    "| 3/21  | 4 PM  | Finished each section of the project | Go over and check the project one last time before submission |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"footnote1\"></a><sup>[1]</sup> NASA. (n.d.). Exoplanet-catalog – exoplanet exploration: Planets beyond our solar system. NASA. Retrieved February 22, 2023, from https://exoplanets.nasa.gov/exoplanet-catalog/5269/kepler-438-b/ \n",
    "\n",
    "<a name=\"footnote2\"></a><sup>[2]</sup> Torres, G., Kipping, D. M., Fressin, F., Caldwell, D. A., Twicken, J. D., Ballard, S., ... & Quintana, E. V. (2015). Validation of 12 small Kepler transiting planets in the habitable zone. The Astrophysical Journal, 800(2), 99.\n",
    "\n",
    "<a name=\"footnote3\"></a><sup>[3]</sup> Bailer-Jones, C. A. (2001). Automated stellar classification for large surveys: a review of methods and results. arXiv preprint astro-ph/0102223.\n",
    "\n",
    "<a name=\"footnote4\"></a><sup>[4]</sup> Baqui, P. O., Marra, V., Casarini, L., Angulo, R., Diaz-Garcia, L. A., Hernández-Monteagudo, C., ... & Taylor, K. (2021). The miniJPAS survey: star-galaxy classification using machine learning. Astronomy & Astrophysics, 645, A87. \n",
    "\n",
    "<a name=\"footnote5\"></a><sup>[5]</sup> Saifuddin, M. (2023, January 3). Stellar classification: A machine learning approach. Medium. Retrieved February 22, 2023, from https://towardsdatascience.com/stellar-classification-a-machine-learning-approach-5e23eb5cadb1 \n",
    "\n",
    "<a name=\"footnote5\"></a><sup>[6]</sup> Shrinivas Kulkarni's webpage. (n.d.). Retrieved February 22, 2023, from https://sites.astro.caltech.edu/~srk/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "363186aa0d6e5fbc80f021484066ca846e3ace2c487d5d1f9d1d88c4b9c13e0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
